{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires pymongo 3.6.0+\n",
    "from pymongo import MongoClient\n",
    "from bson.code import Code\n",
    "import pandas as pd\n",
    "\n",
    "client = MongoClient(\"mongodb://bigdata-mongodb-04.virtual.uniandes.edu.co:8087/\", retryWrites=False)\n",
    "database = client[\"Grupo03\"]\n",
    "collection = database[\"COL_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/\n",
    "\n",
    "query = {}\n",
    "projection = {}\n",
    "projection[\"reply_or_quote\"] = 1.0\n",
    "\n",
    "data = []\n",
    "cursor = collection.find(query, projection = projection)\n",
    "try:\n",
    "    for doc in cursor:\n",
    "        data.append([doc['_id'], doc['reply_or_quote']])\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5e95c25095e4b2cefb66fbf2</td>\n",
       "      <td>@ClaudiaLopez @infopresidencia @Bogota Para cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5e95c25095e4b2cefb66fbf3</td>\n",
       "      <td>@ClaudiaLopez @infopresidencia @Bogota La verd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5e95c25095e4b2cefb66fbf4</td>\n",
       "      <td>@ClaudiaLopez @infopresidencia @Bogota Pero, x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5e95c25095e4b2cefb66fbf5</td>\n",
       "      <td>@ClaudiaLopez @infopresidencia @Bogota Ingreso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5e95c25095e4b2cefb66fbf6</td>\n",
       "      <td>@ClaudiaLopez @infopresidencia @Bogota Estimad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                                               text\n",
       "0  5e95c25095e4b2cefb66fbf2  @ClaudiaLopez @infopresidencia @Bogota Para cu...\n",
       "1  5e95c25095e4b2cefb66fbf3  @ClaudiaLopez @infopresidencia @Bogota La verd...\n",
       "2  5e95c25095e4b2cefb66fbf4  @ClaudiaLopez @infopresidencia @Bogota Pero, x...\n",
       "3  5e95c25095e4b2cefb66fbf5  @ClaudiaLopez @infopresidencia @Bogota Ingreso...\n",
       "4  5e95c25095e4b2cefb66fbf6  @ClaudiaLopez @infopresidencia @Bogota Estimad..."
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data,columns=['_id', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened', 'd', 'x', 'pa', 'q', 'si', 'usted', 'tan', 'solo', 'ser', 'bien', 'así', 'mas', 'va', 'van', 'señor', 'hace', 'hacer', 'siempre', 'gracias', 'favor', 'puede', 'dio', 'como', 'aquí', 'ahí']\n"
     ]
    }
   ],
   "source": [
    "my_stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "stopwords = ['d', 'x', 'pa', 'q', 'si', 'usted', 'tan', 'solo', 'ser', 'bien', 'así', 'mas', 'va', 'van', 'señor', 'hace', 'hacer', \n",
    "             'siempre', 'gracias', 'favor', 'puede', 'dio', 'como', 'aquí', 'ahí']\n",
    "my_stopwords.extend(stopwords)\n",
    "print(my_stopwords)\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df.text.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "# apply transformation\n",
    "tf = vectorizer.fit_transform(df['clean_tweet']).toarray()\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "number_of_topics = 5\n",
    "\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "      <th>Topic 4 words</th>\n",
       "      <th>Topic 4 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>colombia</td>\n",
       "      <td>305.6</td>\n",
       "      <td>gobierno</td>\n",
       "      <td>259.1</td>\n",
       "      <td>paí</td>\n",
       "      <td>295.8</td>\n",
       "      <td>dio</td>\n",
       "      <td>274.2</td>\n",
       "      <td>ayuda</td>\n",
       "      <td>366.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>petro</td>\n",
       "      <td>193.2</td>\n",
       "      <td>estrato</td>\n",
       "      <td>170.6</td>\n",
       "      <td>president</td>\n",
       "      <td>223.7</td>\n",
       "      <td>senador</td>\n",
       "      <td>167.7</td>\n",
       "      <td>gent</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mejor</td>\n",
       "      <td>183.4</td>\n",
       "      <td>pueblo</td>\n",
       "      <td>134.2</td>\n",
       "      <td>alcald</td>\n",
       "      <td>188.1</td>\n",
       "      <td>urib</td>\n",
       "      <td>165.1</td>\n",
       "      <td>persona</td>\n",
       "      <td>202.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cuba</td>\n",
       "      <td>182.2</td>\n",
       "      <td>ayuda</td>\n",
       "      <td>130.8</td>\n",
       "      <td>día</td>\n",
       "      <td>144.5</td>\n",
       "      <td>noticia</td>\n",
       "      <td>153.3</td>\n",
       "      <td>meno</td>\n",
       "      <td>182.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>salud</td>\n",
       "      <td>179.6</td>\n",
       "      <td>recurso</td>\n",
       "      <td>121.9</td>\n",
       "      <td>colombia</td>\n",
       "      <td>130.9</td>\n",
       "      <td>grand</td>\n",
       "      <td>138.7</td>\n",
       "      <td>alcaldesa</td>\n",
       "      <td>163.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>fuerza</td>\n",
       "      <td>153.2</td>\n",
       "      <td>robar</td>\n",
       "      <td>117.3</td>\n",
       "      <td>ahora</td>\n",
       "      <td>126.4</td>\n",
       "      <td>president</td>\n",
       "      <td>137.3</td>\n",
       "      <td>claudia</td>\n",
       "      <td>123.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>médico</td>\n",
       "      <td>141.9</td>\n",
       "      <td>dinero</td>\n",
       "      <td>114.3</td>\n",
       "      <td>gent</td>\n",
       "      <td>122.1</td>\n",
       "      <td>buena</td>\n",
       "      <td>132.5</td>\n",
       "      <td>dio</td>\n",
       "      <td>109.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>colombiano</td>\n",
       "      <td>137.1</td>\n",
       "      <td>servicio</td>\n",
       "      <td>113.2</td>\n",
       "      <td>caso</td>\n",
       "      <td>114.0</td>\n",
       "      <td>mano</td>\n",
       "      <td>118.1</td>\n",
       "      <td>banco</td>\n",
       "      <td>109.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>mucha</td>\n",
       "      <td>131.2</td>\n",
       "      <td>hp</td>\n",
       "      <td>111.2</td>\n",
       "      <td>gobierno</td>\n",
       "      <td>110.6</td>\n",
       "      <td>petro</td>\n",
       "      <td>110.1</td>\n",
       "      <td>empresa</td>\n",
       "      <td>108.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>mismo</td>\n",
       "      <td>119.8</td>\n",
       "      <td>plata</td>\n",
       "      <td>100.7</td>\n",
       "      <td>da</td>\n",
       "      <td>105.3</td>\n",
       "      <td>ud</td>\n",
       "      <td>103.7</td>\n",
       "      <td>familia</td>\n",
       "      <td>108.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
       "0      colombia           305.6      gobierno           259.1           paí   \n",
       "1         petro           193.2       estrato           170.6     president   \n",
       "2         mejor           183.4        pueblo           134.2        alcald   \n",
       "3          cuba           182.2         ayuda           130.8           día   \n",
       "4         salud           179.6       recurso           121.9      colombia   \n",
       "5        fuerza           153.2         robar           117.3         ahora   \n",
       "6        médico           141.9        dinero           114.3          gent   \n",
       "7    colombiano           137.1      servicio           113.2          caso   \n",
       "8         mucha           131.2            hp           111.2      gobierno   \n",
       "9         mismo           119.8         plata           100.7            da   \n",
       "\n",
       "  Topic 2 weights Topic 3 words Topic 3 weights Topic 4 words Topic 4 weights  \n",
       "0           295.8           dio           274.2         ayuda           366.5  \n",
       "1           223.7       senador           167.7          gent           214.3  \n",
       "2           188.1          urib           165.1       persona           202.2  \n",
       "3           144.5       noticia           153.3          meno           182.4  \n",
       "4           130.9         grand           138.7     alcaldesa           163.5  \n",
       "5           126.4     president           137.3       claudia           123.2  \n",
       "6           122.1         buena           132.5           dio           109.6  \n",
       "7           114.0          mano           118.1         banco           109.2  \n",
       "8           110.6         petro           110.1       empresa           108.9  \n",
       "9           105.3            ud           103.7       familia           108.6  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
