{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires pymongo 3.6.0+\n",
    "from pymongo import MongoClient\n",
    "from bson.code import Code\n",
    "\n",
    "client = MongoClient(\"mongodb://bigdata-mongodb-04.virtual.uniandes.edu.co:8087/\", retryWrites=False)\n",
    "database = client[\"Grupo03\"]\n",
    "collection = database[\"ARG_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = Code(\"function () {\"\n",
    "            'var regex = /[!\"#$%&' + \"'()*+,-./:;<=>?[\\]^_`{|}~]/g;\"\n",
    "            \"var palabras = this.reply_or_quote.split(' ');\"       \n",
    "            \"palabras.forEach(function(z) {\"\n",
    "            \"z = z.replace(regex, '');\"\n",
    "            \"z = z.replace(/\\\\n/g,\"\");\"\n",
    "            \"emit(z.toLowerCase(), 1);\"\n",
    "            \"});\"\n",
    "            \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = Code(\"function (key, values) {\"\n",
    "               \"  var total = 0;\"\n",
    "               \"  for (var i = 0; i < values.length; i++) {\"\n",
    "               \"    total += values[i];\"\n",
    "               \"  }\"\n",
    "               \"  return total;\"\n",
    "               \"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contador de palabras / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = database.COL_dataset.map_reduce(map, reduce, \"emociones\")\n",
    "#for doc in result.find():\n",
    "#    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('spanish')) \n",
    "\n",
    "collection = database[\"emociones\"]\n",
    "query = {}\n",
    "query[\"_id\"] = {\n",
    "    u\"$exists\": True\n",
    "}\n",
    "\n",
    "projection = {}\n",
    "projection[\"_id\"] = 1.0\n",
    "stopwords = {'q', 'si', 'usted', 'tan', 'solo', 'ser', 'bien', 'as√≠', 'mas', 'va', 'van', 'se√±or', 'hace', 'hacer', \n",
    "             'siempre', 'gracias', 'favor', 'puede'}\n",
    "stop_words.update(stopwords)\n",
    "\n",
    "cursor = collection.find(query, projection = projection)\n",
    "try:\n",
    "    for doc in cursor:\n",
    "        if (doc['_id'] in stop_words or (doc['_id'][0:1] == '@')):\n",
    "            collection.delete_one({'_id': doc['_id']})\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "collection = database[\"ARG_dataset\"]\n",
    "\n",
    "# Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/\n",
    "\n",
    "query = {}\n",
    "projection = {}\n",
    "projection[\"reply_or_quote\"] = 1.0\n",
    "\n",
    "data = []\n",
    "cursor = collection.find(query, projection = projection)\n",
    "try:\n",
    "    for doc in cursor:\n",
    "        data.append([doc['_id'], doc['reply_or_quote']])\n",
    "finally:\n",
    "    client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e91f3c26de7b8ddc68afa72</td>\n",
       "      <td>@alferdez Por favor Alberto segu√≠ con la cuare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e91f3cf6de7b8ddc68afa73</td>\n",
       "      <td>@alferdez Grandes se√±or Presidente no le vot√©?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e91f3cf6de7b8ddc68afa74</td>\n",
       "      <td>@alferdez Gracias a usted, presidente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e91f3cf6de7b8ddc68afa75</td>\n",
       "      <td>@alferdez Si no ayudas a las pymes,hasta ahora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e91f3cf6de7b8ddc68afa76</td>\n",
       "      <td>@alferdez Gracias ‚ù§\\nüíïGracias\\nGracias ‚úå‚ù§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                                               text\n",
       "0  5e91f3c26de7b8ddc68afa72  @alferdez Por favor Alberto segu√≠ con la cuare...\n",
       "1  5e91f3cf6de7b8ddc68afa73  @alferdez Grandes se√±or Presidente no le vot√©?...\n",
       "2  5e91f3cf6de7b8ddc68afa74              @alferdez Gracias a usted, presidente\n",
       "3  5e91f3cf6de7b8ddc68afa75  @alferdez Si no ayudas a las pymes,hasta ahora...\n",
       "4  5e91f3cf6de7b8ddc68afa76          @alferdez Gracias ‚ù§\\nüíïGracias\\nGracias ‚úå‚ù§"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data,columns=['_id', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def get_top_n_words(corpus, n=1,k=1):\n",
    "    vec = CountVectorizer(ngram_range=(k,k),stop_words = stop_words).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_pos = ['nc00000', 'nc0n000', 'nc0p000', 'nc0s000', 'np00000']\n",
    "\n",
    "def ExtractInteresting(sentence, good):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    interesting = [k for k,v in nltk.pos_tag(words) if v in good]\n",
    "    print(interesting)\n",
    "    return(interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "import re\n",
    "\n",
    "tagger=\"stanford-postagger-full-2018-10-16/models/spanish.tagger\"\n",
    "jar=\"stanford-postagger-full-2018-10-16/stanford-postagger.jar\"\n",
    "\n",
    "spanish_postagger = StanfordPOSTagger(tagger,jar, encoding='utf8')\n",
    "\n",
    "\n",
    "sentences = ['@ClaudiaLopez @infopresidencia @Bogota La verdad esa ayuda es una  mentira soy madre cabeza de familia no aparezco en el Sisben y a√∫n Haci no he resubido ning√∫n ayuda se supo e que las personas que no aparecen en el Sisben las localizavan de otra forma @ClaudiaLopez me urge una ayuda','@ClaudiaLopez @infopresidencia @Bogota no se se√±ora alcaldesa si podamos contar con si apoyo ya q debido a esta emergencia mundial no he podido trabajar üòîagradeceria nos tenga en cuenta mi puntaje en el sisben es 18.47 y mi nivel es 1 quedo atenta a alg√∫n recibido sra claudia bendiciones y q mi Dios la proteja']\n",
    "\n",
    "nouns = []\n",
    "for index, row in df.iterrows():\n",
    "    words = row['text'].split()\n",
    "    tagged_words = spanish_postagger.tag(words)\n",
    "    palabra_anterior = ''\n",
    "    for (word, tag) in tagged_words:\n",
    "        if tag in good_pos:\n",
    "            if not ((word[0:1] == '@') or (word[0:4] == 'http')):\n",
    "                word = re.sub(r'[^\\w\\s]','',word)\n",
    "                #print(word+' '+tag)\n",
    "                if palabra_anterior != '' and word != '':\n",
    "                    pareja = palabra_anterior + ' ' + word\n",
    "                    nouns.append(pareja.lower())\n",
    "                palabra_anterior = word\n",
    "#    del nouns[0]\n",
    "#print(nouns)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnouns = pd.DataFrame(nouns, columns=['text'])\n",
    "collection_dataset = database[\"ARG_temas\"]\n",
    "\n",
    "for indice_fila, fila in dfnouns.iterrows():\n",
    "    tweet = {'id': fila.text, 'frecuencia': ''}\n",
    "    collection_dataset.insert_one(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = get_top_n_words(dfnouns['text'], 20,2)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "df = pd.DataFrame(common_words, columns = ['ReviewText' , 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce (temas frecuentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = database[\"ARG_temas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = Code(\"function () {\"\n",
    "            \"var palabras = this.id;\"            \n",
    "            \"emit(palabras, 1);\"            \n",
    "            \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = Code(\"function (key, values) {\"\n",
    "               \"  var total = 0;\"\n",
    "               \"  for (var i = 0; i < values.length; i++) {\"\n",
    "               \"    total += values[i];\"\n",
    "               \"  }\"\n",
    "               \"  return total;\"\n",
    "               \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = database.ARG_temas.map_reduce(map, reduce, \"ARG_temas_cuenta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
